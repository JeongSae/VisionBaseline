{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "916cd4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2b8519",
   "metadata": {},
   "source": [
    "## vgg functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bdd6810",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBnRelu(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, kernel_size, stride, padding):\n",
    "        super(ConvBnRelu, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels=in_ch, out_channels=out_ch, kernel_size=kernel_size,\n",
    "                              stride=stride, padding=padding)\n",
    "        self.bn = nn.BatchNorm2d(out_ch)\n",
    "        self.relu = nn.ReLU6(inplace=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = self.bn(out)\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "    \n",
    "class DenseBnRelu(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, drop_rate):\n",
    "        super(DenseBnRelu, self).__init__()\n",
    "        self.linear = nn.Linear(in_ch, out_ch)\n",
    "        self.bn = nn.BatchNorm1d(out_ch)\n",
    "        self.relu = nn.ReLU6(inplace=False)\n",
    "        self.drop = nn.Dropout(drop_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.drop(x)\n",
    "        out = self.linear(out)\n",
    "        out = self.bn(out)\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "    \n",
    "class ConvRelu(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, kernel_size, stride, padding, LPN=False):\n",
    "        super(ConvRelu, self).__init__()\n",
    "        self.LPN = LPN\n",
    "        self.conv = nn.Conv2d(in_channels=in_ch, out_channels=out_ch, kernel_size=kernel_size,\n",
    "                              stride=stride, padding=padding)\n",
    "        self.relu = nn.ReLU(inplace=False)\n",
    "        if self.LPN:\n",
    "            self.lpn = nn.LocalResponseNorm(2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        if self.LPN:\n",
    "            out = self.lpn(out)\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "    \n",
    "class DenseRelu(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, drop_rate):\n",
    "        super(DenseRelu, self).__init__()\n",
    "        self.linear = nn.Linear(in_ch, out_ch)\n",
    "        self.relu = nn.ReLU(inplace=False)\n",
    "        self.drop = nn.Dropout(drop_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.drop(x)\n",
    "        out = self.linear(out)\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "class VGG(nn.Module):\n",
    "    def __init__(self, num_channels, num_layers, num_class, drop_rate, version, depth=[1, 2, 4, 8, 8]):\n",
    "        super(VGG, self).__init__()\n",
    "        \n",
    "        # init\n",
    "        self.channels = num_channels[0]\n",
    "        \n",
    "        # construct\n",
    "        out_channels, layers, classifier = 64, [], []\n",
    "        \n",
    "        if num_channels[1] == 32:\n",
    "            out_dim = 512\n",
    "        elif num_channels[1] == 224:\n",
    "            out_dim = 25088\n",
    "        \n",
    "        # get layers\n",
    "        # in_ch, out_ch, kernel_size, stride, padding\n",
    "        if 'advanced' in version:\n",
    "            print('Advanced VGG')\n",
    "            ch_remember = 64\n",
    "            for i in range(len(num_layers)):\n",
    "                for num in range(num_layers[i]):\n",
    "                    if i == 0 and len(layers) == 0:\n",
    "                        layers.append(ConvBnRelu(self.channels, out_channels * depth[i], 3, 1, 'same'))\n",
    "                        ch_remember = out_channels * depth[i]\n",
    "                    else:\n",
    "                        layers.append(ConvBnRelu(ch_remember, out_channels * depth[i], 3, 1, 'same'))\n",
    "                        ch_remember = out_channels * depth[i]\n",
    "                layers.append(nn.MaxPool2d(kernel_size=2, stride=2, padding=0))\n",
    "            classifier.append(DenseBnRelu(out_dim, 4096, drop_rate))\n",
    "            classifier.append(DenseBnRelu(4096, 4096, drop_rate))\n",
    "        elif 'LRN' in version:\n",
    "            print('LRN VGG')\n",
    "            ch_remember = 64\n",
    "            for i in range(len(num_layers)):\n",
    "                for num in range(num_layers[i]):\n",
    "                    if i == 0:\n",
    "                        layers.append(ConvRelu(self.channels, out_channels * depth[i], 3, 1, 'same'))\n",
    "                        ch_remember = out_channels * depth[i]\n",
    "                    else:\n",
    "                        layers.append(ConvRelu(ch_remember, out_channels * depth[i], 3, 1, 'same'))\n",
    "                        ch_remember = out_channels * depth[i]\n",
    "                layers.append(nn.MaxPool2d(kernel_size=2, stride=2, padding=0))\n",
    "            classifier.append(DenseRelu(out_dim, 4096, drop_rate))\n",
    "            classifier.append(DenseRelu(4096, 4096, drop_rate))\n",
    "        elif 'v1' in version:\n",
    "            print('VGG16 Version 1')\n",
    "            ch_remember = 64\n",
    "            for i in range(len(num_layers)):\n",
    "                for num in range(num_layers[i]):\n",
    "                    if i == 0 and len(layers) == 0:\n",
    "                        layers.append(ConvRelu(self.channels, out_channels * depth[i], 3, 1, 'same'))\n",
    "                        ch_remember = out_channels * depth[i]\n",
    "                    elif i > 1 and num == num_layers[i]-1:\n",
    "                        layers.append(ConvRelu(ch_remember, out_channels * depth[i], 1, 1, 'same'))\n",
    "                        ch_remember = out_channels * depth[i]\n",
    "                    else:\n",
    "                        layers.append(ConvRelu(ch_remember, out_channels * depth[i], 3, 1, 'same'))\n",
    "                        ch_remember = out_channels * depth[i]\n",
    "                layers.append(nn.MaxPool2d(kernel_size=2, stride=2, padding=0))\n",
    "            classifier.append(DenseRelu(out_dim, 4096, drop_rate))\n",
    "            classifier.append(DenseRelu(4096, 4096, drop_rate))\n",
    "        elif 'v2' in version:\n",
    "            print('VGG16 Version 2')\n",
    "            ch_remember = 64\n",
    "            for i in range(len(num_layers)):\n",
    "                for num in range(num_layers[i]):\n",
    "                    if i == 0 and len(layers) == 0:\n",
    "                        layers.append(ConvRelu(self.channels, out_channels * depth[i], 3, 1, 'same'))\n",
    "                        ch_remember = out_channels * depth[i]\n",
    "                    else:\n",
    "                        layers.append(ConvRelu(ch_remember, out_channels * depth[i], 3, 1, 'same'))\n",
    "                        ch_remember = out_channels * depth[i]\n",
    "                layers.append(nn.MaxPool2d(kernel_size=2, stride=2, padding=0))\n",
    "            classifier.append(DenseRelu(out_dim, 4096, drop_rate))\n",
    "            classifier.append(DenseRelu(4096, 4096, drop_rate))\n",
    "        else:\n",
    "            print('Normal Version')\n",
    "            ch_remember = 64\n",
    "            for i in range(len(num_layers)):\n",
    "                for num in range(num_layers[i]):\n",
    "                    if i == 0 and len(layers) == 0:\n",
    "                        layers.append(ConvRelu(self.channels, out_channels * depth[i], 3, 1, 'same'))\n",
    "                        ch_remember = out_channels * depth[i]\n",
    "                    else:\n",
    "                        layers.append(ConvRelu(ch_remember, out_channels * depth[i], 3, 1, 'same'))\n",
    "                        ch_remember = out_channels * depth[i]\n",
    "                layers.append(nn.MaxPool2d(kernel_size=2, stride=2, padding=0))\n",
    "            classifier.append(DenseRelu(out_dim, 4096, drop_rate))\n",
    "            classifier.append(DenseRelu(4096, 4096, drop_rate))\n",
    "        \n",
    "        # create model\n",
    "        classifier.append(nn.Linear(4096, num_class))\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        self.classifier = nn.Sequential(*classifier)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layers(x)\n",
    "        out = self.flatten(out)\n",
    "        out = self.classifier(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8eb2aaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg(num_class, input_shape, dropout, layers, version='vgg16'):\n",
    "    print(f'---- version : {version}  num layers : {layers}  num class : {num_class}  input shape : {input_shape}  drop rate : {dropout} ----')\n",
    "    model = VGG(input_shape, layers, num_class, dropout, version)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "268a222b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- version : vgg19_advanced  num layers : [2, 2, 4, 4, 4]  num class : 102  input shape : (3, 224, 224)  drop rate : 0.5 ----\n",
      "Advanced VGG\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 102])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "version_dict = {'vgg11' : [1, 1, 2, 2, 2],\n",
    "                'vgg11_LRN' : [1, 1, 2, 2, 2],\n",
    "                'vgg13' : [2, 2, 2, 2, 2],\n",
    "                'vgg16_v1' : [2, 2, 3, 3, 3],\n",
    "                'vgg16_v2' : [2, 2, 3, 3, 3],\n",
    "                'vgg16_advanced' : [2, 2, 3, 3, 3],\n",
    "                'vgg19' : [2, 2, 4, 4, 4],\n",
    "                'vgg19_advanced' : [2, 2, 4, 4, 4]}\n",
    "\n",
    "# hyper parameters\n",
    "select_version = 'vgg19_advanced'\n",
    "num_class = 102\n",
    "image_size = 224\n",
    "input_shape = (3, 224, 224)\n",
    "dropout = 0.5\n",
    "\n",
    "# construct\n",
    "model = vgg(num_class, input_shape, dropout, version_dict[select_version], select_version)\n",
    "\n",
    "# testing\n",
    "sample = torch.Tensor(np.array(range(4*3*224*224)).reshape(4, 3, 224, 224))\n",
    "model(sample).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work",
   "language": "python",
   "name": "workspace"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
